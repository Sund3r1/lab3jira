**Лабораторная работа 2. "Битва Титанов: AWS против Azure"**

**Задание**

Провести сравнение облачных сервисов Amazon Web Services и Microsoft Azure. Главная цель — создать единую кросс-провайдерную сервисную модель, абстрагируясь от конкретных названий вендоров, и доказать, что облако — это концепция, а не просто набор брендов.

**Ход работы**

**Наследие первой лаборатории**

В первой части мы уже разобрались с AWS. Там всё было разложено по полочкам: Compute к Compute, S3 к Storage. Мы создали "золотой стандарт" классификации. Казалось бы, полдела сделано.

Но, как известно, каждый облачный провайдер считает своим долгом назвать одни и те же вещи по-разному, чтобы жизнь инженера не казалась сказкой. Перед нами встала задача: взять сырой биллинг от Microsoft Azure и, не сломав логику, натянуть его на структуру, разработанную для AWS.

**Импорт и первое знакомство**

Первым делом файл .csv с данными Azure был импортирован в Excel.  
Сырые данные выглядели как набор разрозненных сервисов: какие-то Container Instances, загадочная Cortana Intelligence, Bandwidth и Data Box.

Главная проблема заключалась в том, что Azure использует другую терминологию. Если в AWS у нас есть четкий "EC2", то в Azure вычислительные ресурсы могут скрываться под десятком разных имен.

**Этап 1: Вычислительные мощности (Compute)**

В AWS мы относили Amazon EC2 к категории **Compute**.  
В Azure мы увидели Container Instances и Container Registry.

**Ход мысли:**

1.  Контейнеры — это, по сути, те же вычисления, только упакованные иначе. Они потребляют CPU и Память.
2.  Значит, следуя логике первой лабы, это однозначно **Compute**.
3.  Разбиение на подтипы: Core Duration (время работы ядра) — это использование, а Registry Unit — это хранение образов, но всё еще в рамках вычислительной семьи.

Таким образом, группа **Compute** была успешно сформирована.

**Этап 2: Сетевой детектив (Networking)**

С сетью пришлось провести небольшое расследование.  
В данных Azure были строки Bandwidth, Network Watcher и Application Gateway.

- **Bandwidth:** По сути — это трафик. В AWS это называлось Data Transfer. Значит — **Networking**.
- **Application Gateway:** Это балансировщик нагрузки (L7). В AWS аналогом был CloudFront или ALB. Однозначно — **Networking**.
- **Network Watcher:** Инструмент мониторинга сети. Логично оставить его в сетевой башне.

**Этап 3: Данные и где они обитают (Storage & Database)**

Самая хитрая часть. В AWS всё было просто: RDS — это база, S3 — это хранилище.  
В Azure нас встретили:

1.  Data Lake Store и Data Box.
    - Data Lake — это "озеро данных", по сути, бесконечное хранилище. Аналог S3. Отправляем в **Storage**.
    - Data Box — это физическая коробка с дисками для импорта. Тоже **Storage**.
2.  SQL Data Warehouse и Data Management.
    - Тут пришлось включить логику. SQL — это очевидно база данных.
    - А что такое Data Management с параметром Geo-Replicated Data Transfer? Это репликация базы данных. Значит, это семья **Database**.

**Сведение единой модели**

После того как каждый сервис Azure прошел через "фильтр логики AWS", мы получили единую структуру.

**Слева** — наша универсальная классификация (IT Tower / Service Family).  
**Справа** — оригинальные названия сервисов Azure.

Это позволяет нам смотреть на облако "сверху". Неважно, используем ли мы Amazon Kendra или Azure Cortana Intelligence — для бизнеса это всё равно **Artificial Intelligence** в башне **Cloud Services**.

Итоговая таблица сопоставления выглядит следующим образом:

А для сравнения, вот как это выглядело в AWS:

**Вывод**

В ходе лабораторной работы была выполнена аналитическая задача по унификации облачных сервисов.  
Нам удалось:

1.  Преодолеть маркетинговые названия сервисов и добраться до их технической сути.
2.  Построить иерархию, где Compute, Networking, Storage и Database являются универсальными константами, независимо от того, чьи серверы мы арендуем — Джеффа Безоса или Microsoft.
3.  Доказать, что навыки классификации сервисов позволяют легко ориентироваться в биллинге любого провайдера, даже если вы видите его впервые.

Теперь, имея две идентичные по структуре таблицы, можно проводить кросс-провайдерный анализ затрат, что и являлось конечной целью создания сервисной модели.
